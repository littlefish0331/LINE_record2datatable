---
title: "01_rawdata_process_phone"
author: "Steve, Yu"
date: "2020/5/11"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls()); gc()
library(dplyr)
library(data.table)
library(lubridate)
library(zoo)
library(Nippon)
library(knitr)
opts_chunk$set(echo = TRUE)
```

# File Target

此檔案以**手機板的匯出格式**為主。

- 讀取資料
- 擷取匯出的標頭
  - 存檔
- 清理多行訊息
  - 清除空行
  - \t格式填補
  - 判斷是否多行數訊息
  - 多行數訊息合併
- 欄位特徵
  - 日期-timedate
  - 星期幾-weekday
  - 時間-timestamp
  - 用戶-user
  - 內文-context
  - 存檔
- 每日統計
  - 每日用戶訊息統計
  - 每日訊息統計
- 訊息類型

--

統計 function。

```{r}
pattern.count <- function(x, pattern){
  res <- x %>% 
    gregexpr(pattern, .) %>% 
    lapply(., function(x) sum(x!=-1) ) %>% unlist()
  return(res)
}

pattern.exist <- function(x, pattern, ...){
  res <- x %>% grepl(pattern, ., ...)
  return(res)
}
```

---

# 讀取資料

```{r}
# 這個方法會有 bom 的問題。
# 但是空行會留著
raw <- readLines("../data/phone/[LINE] NCHC Data Analysis的聊天.txt", encoding = "UTF-8")
raw %>% head(10)

# ---
# 沒有 bom 問題。但我不想這麼早就變成 data.table。
# raw <- fread("../data/phone/[LINE] NCHC Data Analysis的聊天.txt", 
#              encoding = "UTF-8", sep = "", sep2 = "", header = F, col.names = "raw_context")
# raw %>% head(10)
```

---

# 擷取匯出的標頭

- 第一行為聊天視窗名稱
- 第二行為紀錄匯出的時間
- 第四行為紀錄起始的時間

```{r}
filename_n1 <- raw[1] %>% 
  sub("\\[LINE\\] ", "", .) %>% 
  sub("(.*)的聊天記錄$", "\\1", .) %>% 
  zen2han() %>% 
  gsub(" ", "_", .)
tt <- filename_n1 %>% charToRaw() %>% head(3)
if (sum(tt==c("ef", "bb", "bf"))==3) {
  filename_n1 <- filename_n1 %>% 
    charToRaw() %>% tail(-3) %>% rawToChar() %>% 
    iconv(x = ., from = "UTF-8", "UTF-8")
}

filename_n2 <- raw[4] %>% 
  sub("([0-9]{4}/[0-9]{2}/[0-9]{2})(.*)", "\\1", .) %>% 
  gsub("/", "", .)

filename_n3 <- raw[2] %>% 
  sub("(.*)([0-9]{4}/[0-9]{2}/[0-9]{2})(.*)", "\\2", .) %>% 
  gsub("/", "", .)

filename <- paste(filename_n1, filename_n2, filename_n3, sep = "-")
raw_context <- raw[-c(1:2)]
```

--

## 存檔

useBytes = T，確保 UTF-8 編碼。

```{r}
nn <- paste0("../data_clean/", filename, ".txt")
writeLines(text = raw_context, con = nn, useBytes = T)
```

---

# 清理訊息

- [R-append lines to a created file](https://stat.ethz.ch/pipermail/r-help/2008-December/182849.html)
- [r - use sink with UTF-8 encoding - Stack Overflow](https://stackoverflow.com/questions/38955337/use-sink-with-utf-8-encoding)

```{r echo = F}
rm(list = setdiff(ls(), c(lsf.str(), "filename")))
invisible(gc())
```

讀取檔案。

```{r}
tmp01 <- readLines("../data_clean/NCHC_Data_Analysis-20200721-20201001.txt", encoding = "UTF-8")
tmp01 %>% head()
```

--

## 清除空行。

```{r}
idx.daily_begin <- tmp01 %>% grepl("^[0-9]{4}/[0-9]{2}/[0-9]{2}.{3}$", .) %>% which
idx.plain_line <- idx.daily_begin - 1
tmp02 <- tmp01[-idx.plain_line]

# ---
# 控行沒有消失，只是 print 出來會看不到而已。
# tmp02 <- data.table(raw_context = tmp01)
```

--

## `\t`格式填補01

- FSI, PDI 符號清理 <U+2068>, <U+2069>。
- 多個連續重複 \t 清理為一個。
- 收回訊息。
  - 下午06:28\t您已收回訊息
  - 下午01:28\tYou unsent a message.
- 相簿操作。
  - 下午04:48\tAnnie刪除了「XXX」相簿內的照片
  - 下午07:25\t余佑駿（little fish）已將相簿名稱由「XXX」改為「XXX」
  - 下午09:43\tAnnie changed the name of the album \"XXX\" to \"XXX\".

```{r}
tmp02 <- tmp02 %>% 
  gsub("(\u2068|\u2069)", "", .) %>% 
  gsub("(\t)+", "\t", .) %>% 
  gsub("(.*\t.*)(已收回訊息)$", "\\1\t\\2", .) %>% 
  gsub("(.*\t.*) (unsent a message.)$", "\\1\t\\2", .) %>% 
  gsub("(.*\t.*)(刪除了.*相簿內的照片)$", "\\1\t\\2", .) %>% 
  gsub("(.*\t.*)(已將相簿名稱由.*改為.*)$", "\\1\t\\2", .) %>% 
  gsub("(.*\t.*) (changed the name of the album.*to.*)$", "\\1\t\\2", .)
```

--

## 判斷是否多行數訊息。

```{r}
is.daily_begin <- tmp02 %>% 
  grepl("^[0-9]{4}/[0-9]{2}/[0-9]{2}.{3}$", .) %>% ifelse(., 1, 0)
is.msg_begin <- tmp02 %>% 
  grepl("(上午|下午)[0-9]{2}:[0-9]{2}\t.*", .) %>% ifelse(., 1, 0)
is.single_line <- ifelse((is.daily_begin + is.msg_begin)==0, 0, 1)
```

--

## 多行數訊息合併

轉換成 data.table，並把屬於同一次的訊息 group by 起來。

```{r}
tmp03 <- data.table(raw_context = tmp02, 
                    single_line = is.single_line, 
                    group_line = cumsum(is.single_line)) %>% 
  .[, .(combine_context = paste0(raw_context, collapse = "\n")), by = group_line]
```

--

## `\t`格式填補02

而訊息中有時會因為排版，出現多次 \t，  
經過上面的清理後，保留前兩個，刪除後續出現的 \t，改用空白取代。

```{r}
t1 <- tmp03$combine_context %>% pattern.count(., pattern = "\t")

if (sum(t1==1)>0){
  idx <- which(t1==1)
  msg_format_err <- tmp03$combine_context[idx]
  con <- file("../data_clean/msg_format_err.txt", open = "awt", encoding = "UTF-8")
  sink(file = con)
  msg_format_err
  sink()
  close(con = con)
  
  # ---
  # sink 匯出會是R的結果，保留了 \n\t。
  # 但是 writeLines 會依照 \n\t 等作輸出。
  # con <- file("../data_clean/msg_format_err.txt", open = "awt", encoding = "UTF-8")
  # writeLines(text = msg_format_err, con = con, useBytes = F)
  # close(con = con)
}

if (sum(t1>2)>0) {
  idx <- which(t1>2)
  for (idx_i in 1:length(idx)) {
    tt1 <- idx[idx_i]
    t2_in_context <- tmp03$combine_context[tt1] %>% gregexpr("\t", .) %>% `[[`(1) %>% `[`(2)
    tt2 <- tmp03$combine_context[tt1] %>% 
      substring(., first = 1, last = t2_in_context)
    tt3 <- tmp03$combine_context[tt1] %>% 
      substring(., first = t2_in_context+1, last = nchar(tmp03$combine_context[tt1])) %>% 
      gsub("\t", " ", .)
    tmp03$combine_context[tt1] <- paste0(tt2, tt3)
  }
}
```

---

# 欄位特徵

- [r - Split text string in a data.table columns - Stack Overflow](https://stackoverflow.com/questions/18154556/split-text-string-in-a-data-table-columns)
- [r - Convert 12 hour character time to 24 hour - Stack Overflow](https://stackoverflow.com/questions/29833538/convert-12-hour-character-time-to-24-hour): %p，會隨著語系有所不同("AM/PM" 變成 "上午/下午")
- [R Extract Hours from Time in factor Format - Stack Overflow](https://stackoverflow.com/questions/33903883/r-extract-hours-from-time-in-factor-format/33904124)
- [r - How to fill NAs with LOCF by factors in data frame, split by country - Stack Overflow](https://stackoverflow.com/questions/13616965/how-to-fill-nas-with-locf-by-factors-in-data-frame-split-by-country)

```{r echo = F}
rm(list = setdiff(ls(), c(lsf.str(), "filename", "tmp03")))
invisible(gc())
```

--

## 日期-timedate

yyyy-mm-dd。

```{r}
idx.daily_begin <- tmp03$combine_context %>% 
  grepl("^[0-9]{4}/[0-9]{2}/[0-9]{2}.{3}$", .) %>% which
tmp <- rep(NA, nrow(tmp03))
tmp[idx.daily_begin+1] <- tmp03$combine_context[idx.daily_begin] %>% 
  gsub("/", "-", .) %>% gsub("(（|）|一|二|三|四|五|六|日)", "", .)
tmp03[, `:=`(timedate = tmp)]
```

--

## 星期幾-weekday

一、二、...、日。(非必要欄位)

```{r}
tmp <- rep(NA, nrow(tmp03))
tmp[idx.daily_begin+1] <- tmp03$combine_context[idx.daily_begin] %>% 
  gsub(".*(一|二|三|四|五|六|日).*", "\\1", .)
tmp03[, `:=`(weekday = tmp)]
```

locf: Last Observation Carried Forward

```{r}
tmp04 <- tmp03[-idx.daily_begin, !"group_line"]
tmp04$timedate <- na.locf(tmp04$timedate, fromLast = F)
tmp04$weekday <- na.locf(tmp04$weekday, fromLast = F)
```

--

## 時間-timestamp

hh:mm，24hrs制。

```{r}
tmp05 <- tmp04[, c("timestamp_12", "user", "context") := tstrsplit(combine_context, "\t", fixed = TRUE)]
tmp05$timestamp <- tmp05$timestamp_12 %>% 
  strptime(., "%p%I:%M") %>% format(., "%H:%M")
tmp06 <- tmp05[, `:=`(iid = 1:nrow(tmp05))
               ][, .(iid, timedate, weekday, timestamp, user, context)]
```

--

## 用戶-user

保持資料原本的使用者名稱。  
已完成。

--

## 內文-context

已完成。  
清理多行訊息所生成的雙引號'"'。

```{r}
tmp06$context <- tmp06$context %>% gsub('^"(.*)"$', "\\1", .)
```

--

## 存檔

```{r}
nn <- paste0("../data_clean/", filename, "-split_col.csv")
fwrite(x = tmp06, file = nn, row.names = F)
```

---

# 每日統計

```{r}
rm(list = setdiff(ls(), lsf.str()))
invisible(gc())
```
  
--

## 每日用戶訊息統計

```{r}
split_col <- fread("../data_clean/NCHC_Data_Analysis-20200721-20201001-split_col.csv", 
                   encoding = "UTF-8")
```

```{r}
daily_summary_user <- split_col[, .(context_num = .N), by = .(timedate, weekday, user)]
fwrite(x = daily_summary_user, 
       file = "../data_clean/NCHC_Data_Analysis-20200721-20201001-daily_summary_user.csv",
       row.names = F)
```

--

## 每日訊息統計

```{r}
daily_summary_total <- split_col[, .(context_num = .N), by = .(timedate, weekday)]
fwrite(x = daily_summary_total, 
       file = "../data_clean/NCHC_Data_Analysis-20200721-20201001-daily_summary_total.csv",
       row.names = F)
```

---

# 訊息類型

```{r}
rm(list = setdiff(ls(), lsf.str()))
invisible(gc())
```

- [How can I match emoji with an R regex? - Stack Overflow](https://stackoverflow.com/questions/43359066/how-can-i-match-emoji-with-an-r-regex): 有三種方法，推薦第三種。我自己有整理一個第四種在 code/。

**R detect unicode, R detect emoji:**

- [r - Automatically escape unicode characters - Stack Overflow](https://stackoverflow.com/questions/25308913/automatically-escape-unicode-characters?rq=1)
- [string - Unable to detect a unicode in R - Stack Overflow](https://stackoverflow.com/questions/52834658/unable-to-detect-a-unicode-in-r)
- [How can I match emoji with an R regex? - Stack Overflow](https://stackoverflow.com/questions/43359066/how-can-i-match-emoji-with-an-r-regex)


讀取資料。

```{r}
split_col <- fread("../data_clean/NCHC_Data_Analysis-20200721-20201001-split_col.csv",
                   encoding = "UTF-8")
```

- 行數 rows。
- 有無網址 is_url: 1/0。
- 是否貼圖 is_sticker: 1/0。
- 是否照片 is_image: 1/0。
- 是否影片 is_video: 1/0。
- 是否檔案 is_file: 1/0。
- 是否語音 is_voice: 1/0。
- 是否記事本 is_note: 1/0。
- 是否建立相簿 is_album: 1/0。
- 是否視訊 is_video_chat: 1/0。
- 有無表情符號 is_emoji: 1/0。
- 是否無接聽(語音或視訊) is_pickup。
- 通話時間 voice_video_length。

```{r}
rows <- pattern.count(x = split_col$context, pattern = "\n") + 1
is_url <- pattern.exist(x = split_col$context, pattern = "(https|http)")
is_sticker <- pattern.exist(x = split_col$context, pattern = "^\\[貼圖\\]$")
is_image <- pattern.exist(x = split_col$context, pattern = "^\\[照片\\]$")
is_video <- pattern.exist(x = split_col$context, pattern = "^\\[影片\\]$")
is_file <- pattern.exist(x = split_col$context, pattern = "^\\[檔案\\]$")
is_voice <- pattern.exist(x = split_col$context, pattern = "^\\[語音訊息\\]$")
is_note <- pattern.exist(x = split_col$context, pattern = "^\\[記事本\\]")
is_album <- pattern.exist(x = split_col$context, pattern = "^\\[[相簿\\] \\(null\\)$")
is_video_chat <- pattern.exist(x = split_col$context, pattern = "^☎")
is_emoji <- pattern.exist(x = split_col$context, pattern = "[\U{1F300}-\U{1F6FF}]", perl = T)
is_nopickup <- pattern.exist(x = split_col$context, pattern = "^☎ 未接來電$")

voice_video_length <- rep("-", nrow(split_col))
idx <- pattern.exist(split_col$context, pattern = "^☎ 通話時間") %>% which
voice_video_length[idx] <- split_col$context[idx] %>% 
  gsub("(.*通話時間)([0-9:]+)", "\\2", .)
```

```{r}
context_extract <- data.table(iid = split_col$iid,
                              rows = rows,
                              is_url = is_url,
                              is_sticker = is_sticker,
                              is_image = is_image, 
                              is_video = is_video,
                              is_file = is_file,
                              is_voice = is_voice,
                              is_note = is_note,
                              is_album = is_album,
                              is_video_chat = is_video_chat, 
                              is_emoji = is_emoji,
                              is_nopickup = is_nopickup,
                              voice_video_length = voice_video_length)
```

---

# END


[r - Creating a named list from two vectors (names, values) - Stack Overflow](https://stackoverflow.com/questions/17842705/creating-a-named-list-from-two-vectors-names-values)
